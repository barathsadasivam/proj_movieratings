{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPVLcDkDvPIw6Wyw7QKXkbP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/barathsadasivam/proj_movieratings/blob/main/moviedata_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "5tM1cCKeSPMR",
        "outputId": "74e3d892-591b-443f-c62c-e19d64065341"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/spark-3.3.4-bin-hadoop3'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q https://dlcdn.apache.org/spark/spark-3.3.4/spark-3.3.4-bin-hadoop3.tgz\n",
        "# Unzip the file\n",
        "!tar xf spark-3.3.4-bin-hadoop3.tgz\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = '/content/spark-3.3.4-bin-hadoop3'\n",
        "!pip install -q findspark\n",
        "import findspark\n",
        "findspark.init()\n",
        "# Check the location for Spark\n",
        "findspark.find()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "from pyspark.sql import functions as F\n",
        "from pyspark.sql.functions import col, row_number\n",
        "from pyspark.sql import SparkSession, Window\n",
        "from pyspark.sql.types import StructType, StructField, IntegerType, StringType\n",
        "import json\n",
        "\n",
        "config_file_path = \"/content/config.json\"\n",
        "\n",
        "# Create a SparkSession\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
        "\n",
        "# Function to read CSV file with error handling\n",
        "def read_csv_with_error_handling(file_path, schema):\n",
        "    try:\n",
        "        return spark.read.csv(file_path, sep='::', schema=schema)\n",
        "    except Exception as e:\n",
        "        print(f\"Error reading file at '{file_path}': {e}\")\n",
        "        raise e  # Raise exception in case of an error\n",
        "\n",
        "# Read configuration from JSON file\n",
        "with open(config_file_path, 'r') as config_file:\n",
        "    config = json.load(config_file)\n",
        "\n",
        "# Extract parameters from the config\n",
        "ratings_path = config['file_paths']['ratings_data']\n",
        "movies_path = config['file_paths']['movies_data']\n",
        "original_ratings_path = config['file_paths']['original_ratings_targetformat']\n",
        "original_movies_path = config['file_paths']['original_movies_targetformat']\n",
        "movie_stats_data_path = config['file_paths']['movie_stats_data']\n",
        "top_3_per_user_data_path = config['file_paths']['top_3_per_user_data']\n",
        "ratings_schemafile_path = config['file_paths']['ratings_schemafile']\n",
        "movies_schemafile_path = config['file_paths']['movies_schemafile']\n",
        "\n",
        "# Load the schema file from the local path\n",
        "with open(ratings_schemafile_path, 'r') as ratings_file:\n",
        "    ratings_schema_data = json.load(ratings_file)\n",
        "\n",
        "# Convert the schema data to StructType\n",
        "ratings_schema = StructType.fromJson(ratings_schema_data)\n",
        "\n",
        "with open(movies_schemafile_path, 'r') as movies_file:\n",
        "    movies_schema_data = json.load(movies_file)\n",
        "\n",
        "movies_schema = StructType.fromJson(movies_schema_data)\n",
        "\n",
        "# Read CSV files with error handling\n",
        "df_ratings = read_csv_with_error_handling(ratings_path, ratings_schema)\n",
        "df_movies = read_csv_with_error_handling(movies_path, movies_schema)\n",
        "\n",
        "# Check if files were successfully read before proceeding\n",
        "if df_ratings and df_movies:\n",
        "  # Schema validation checks\n",
        "  if df_ratings.schema == ratings_schema:\n",
        "      print(\"Ratings data schema matches the expected schema.\")\n",
        "  else:\n",
        "      print(\"Ratings data schema does not match the expected schema.\")\n",
        "      raise Exception(\"Ratings data schema does not match the expected schema\")\n",
        "\n",
        "  if df_movies.schema == movies_schema:\n",
        "      print(\"Movies data schema matches the expected schema.\")\n",
        "  else:\n",
        "      print(\"Movies data schema does not match the expected schema.\")\n",
        "      raise Exception(\"Movies data schema does not match the expected schema\")\n",
        "\n",
        "try:\n",
        "  # Perform aggregation on ratings DataFrame to get statistics per MovieID\n",
        "    df_movie_stats = df_ratings.groupBy(df_ratings.MovieID) \\\n",
        "        .agg(\n",
        "            F.max(df_ratings.Rating).alias(\"MaxRating\"),\n",
        "            F.min(df_ratings.Rating).alias(\"MinRating\"),\n",
        "            F.avg(df_ratings.Rating).alias(\"AvgRating\")\n",
        "        )\n",
        "\n",
        "    # Join movie data with aggregated statistics\n",
        "    df_with_stats = df_movies.join(df_movie_stats, df_movies.MovieID == df_movie_stats.MovieID) \\\n",
        "        .select(df_movies.MovieID, df_movies.Title, df_movies.Genres, df_movie_stats.MinRating, df_movie_stats.MaxRating, df_movie_stats.AvgRating)\n",
        "\n",
        "    # Define a Window function to partition by 'UserID' and order by descending 'Rating'\n",
        "    window_spec = Window.partitionBy(\"UserID\").orderBy(col(\"Rating\").desc())\n",
        "\n",
        "    # Assign row numbers to each row within each partition\n",
        "    df_with_row_numbers = df_ratings.withColumn(\"row_number\", row_number().over(window_spec))\n",
        "\n",
        "    # Select top 3 rows for each UserID ordered by 'row_number'\n",
        "    df_top_3_per_user = df_with_row_numbers.where(col(\"row_number\") <= 3).orderBy(\"UserID\", \"row_number\")\n",
        "\n",
        "    # Join dataframes to get the final desired output\n",
        "    final_output = df_movies.join(df_top_3_per_user, df_movies.MovieID == df_top_3_per_user.MovieID) \\\n",
        "        .select(df_top_3_per_user.UserID, df_top_3_per_user.MovieID, df_movies.Title, df_top_3_per_user.Rating, df_top_3_per_user.row_number)\n",
        "\n",
        "    # Write original and final DataFrames to Parquet format\n",
        "    df_ratings.write.mode('overwrite').parquet(original_ratings_path)\n",
        "    df_movies.write.mode('overwrite').parquet(original_movies_path)\n",
        "    df_with_stats.write.mode('overwrite').parquet(movie_stats_data_path)\n",
        "    final_output.write.mode('overwrite').parquet(top_3_per_user_data_path)\n",
        "except Exception as e:\n",
        "  print(\"Unknown exception occured - {}\".format(str(e)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xcdMHmQRSlGB",
        "outputId": "c20da05d-dd60-4de4-a214-88448ca371fe"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ratings data schema matches the expected schema.\n",
            "Movies data schema matches the expected schema.\n"
          ]
        }
      ]
    }
  ]
}